from fastapi import UploadFile, HTTPException
from PIL import Image
import os
from dotenv import load_dotenv
import pdfplumber
from io import BytesIO
from typing import List, Dict, Union, Optional
from docx import Document
from google.cloud import vision
import io
from google.cloud.vision import ImageAnnotatorClient
import pandas as pd
from letter_format import LetterFormatStorage
# from rag_storage import RAGLegalStorage
from rag_storage_local import RAGLegalStorage
from pydantic_ai import Agent
from pydantic_ai.models.openai import OpenAIModel
from pydantic_ai.models.gemini import GeminiModel
from pydantic import BaseModel
import asyncio
from agentic_doc.parse import parse
from judgement import JudgementStorage
from labour_law import LaborLawStorage
import nest_asyncio
# Load environment variables from .env 
load_dotenv()



class DocumentAnalysisRequest(BaseModel):
    """Request model for document analysis"""
    payslip_text: Optional[str] = None
    contract_text: Optional[str] = None
    attendance_text: Optional[str] = None
    analysis_type: str = "report"
    context: Optional[str] = None

class DocumentAnalysisResponse(BaseModel):
    """Response model for document analysis"""
    legal_analysis: str
    # relevant_laws: List[Dict]
    # relevant_judgements: List[Dict]
    status: str
    analysis_type: str

class DocumentProcessor:
    def __init__(self):
        # Initialize RAG storage
        self.rag_storage = RAGLegalStorage()
        
        # Initialize backward compatibility storages
        self.letter_format = LetterFormatStorage()
        # self.law_storage = LaborLawStorage()
        # self.judgement_storage = JudgementStorage()
        self.law_storage = self.rag_storage
        self.judgement_storage = self.rag_storage
        
        # Initialize PydanticAI model - use Gemini only
        gemini_api_key = os.getenv("GOOGLE_CLOUD_VISION_API_KEY")
        if gemini_api_key:
            self.model = GeminiModel('gemini-2.5-pro', api_key=gemini_api_key)
            self.model_type = "gemini"
        else:
            raise Exception("GEMINI_API_KEY must be set in environment variables")
        # Initialize PydanticAI Agent
        nest_asyncio.apply()
        self.agent = Agent(
            model=self.model,
            result_type=str,
            system_prompt="""You are an expert legal document analyzer specializing in Israeli labor law compliance.

You will be provided with:
1. Relevant labor laws retrieved from a legal database
2. Relevant legal judgements and precedents retrieved from a legal database  
3. Document content to analyze (payslips, contracts, attendance records)
4. Additional context if provided

Your analysis must be based STRICTLY on the provided laws and judgements. Do not use external legal knowledge.

Always respond in Hebrew and follow the specific formatting requirements for each analysis type."""        )
        
        nest_asyncio.apply()
        self.context_agent = Agent(
            model=self.model,
            result_type=str,
            system_prompt="""You are an expert legal document analyzer specializing in Israeli labor law compliance.
                    you have to collect all the context of laws and judgements from the RAG storage to give ai for correct anaslysis.
                    create search queries based on law summaries and the document content provided and use the get_laws tool to retrieve relevant laws and use the get_judgements tool to retrieve relevant judgements related to the case.
                    Always respond in Hebrew.
            """
        )
        
        @self.context_agent.system_prompt
        def dynamic_system_prompt():
            """Dynamic system prompt for context agent"""
            # Get all law summaries from RAG storage
            law_summaries = self.rag_storage.get_all_law_summaries()
            
            if law_summaries:
                print(f"Found {len(law_summaries)} law summaries in the database.")
                summaries_text = "\n".join([f"- {summary}" for summary in law_summaries])
                return f"""
×”×™× ×š ×ž× ×ª×— ×ž×¡×ž×›×™× ×ž×©×¤×˜×™×™× ×ž×•×ž×—×” ×”×ž×ª×ž×—×” ×‘×”×ª××ž×” ×œ×—×•×§×™ ×”×¢×‘×•×“×” ×”×™×©×¨××œ×™×™×.

×”× ×” ×¨×©×™×ž×” ×©×œ ×¡×™×›×•×ž×™ ×—×•×§×™× ×”×–×ž×™× ×™× ×‘×ž××’×¨ ×”× ×ª×•× ×™× ×©× ×™×ª×Ÿ ×œ×—×¤×© ×‘×”×:

{summaries_text}

×¢×œ ×‘×¡×™×¡ ×ª×•×›×Ÿ ×”×ž×¡×ž×›×™× ×©×¡×•×¤×§, ×–×”×” ××ª ×”×ž×•×©×’×™× ×”×ž×©×¤×˜×™×™× ×”×¨×œ×•×•× ×˜×™×™× ×‘×™×•×ª×¨ ×•×¦×•×¨ ×©××™×œ×ª×•×ª ×—×™×¤×•×© ×ž×ª××™×ž×•×ª ×œ×ž×¦×™××ª ×”×—×•×§×™× ×•×”×¤×¡×™×§×•×ª ×”×¨×œ×•×•× ×˜×™×™×.
"""
            else:
                return """
×”×™× ×š ×ž× ×ª×— ×ž×¡×ž×›×™× ×ž×©×¤×˜×™×™× ×ž×•×ž×—×” ×”×ž×ª×ž×—×” ×‘×”×ª××ž×” ×œ×—×•×§×™ ×”×¢×‘×•×“×” ×”×™×©×¨××œ×™×™×.

××™×Ÿ ×›×¨×’×¢ ×¡×™×›×•×ž×™ ×—×•×§×™× ×–×ž×™× ×™× ×‘×ž××’×¨ ×”× ×ª×•× ×™×. × ×ª×— ××ª ×ª×•×›×Ÿ ×”×ž×¡×ž×›×™× ×•×¦×•×¨ ×©××™×œ×ª×•×ª ×—×™×¤×•×© ×¢×œ ×‘×¡×™×¡ ×”×ž×•×©×’×™× ×”×ž×©×¤×˜×™×™× ×”×›×œ×œ×™×™× ×”×§×™×™×ž×™×.
"""
        @self.context_agent.tool_plain
        async def get_laws(query: str, max_laws: int = 5) -> List[Dict]:
            """Retrieve relevant labor laws based on query"""
            print(f"Searching for laws with query: {query}")
            return self.rag_storage.search_laws(query, n_results=max_laws)
        
        @self.context_agent.tool_plain
        async def get_judgements(query: str, max_judgements: int = 3) -> List[Dict]:
            """Retrieve relevant legal judgements based on query"""
            print(f"Searching for judgements with query: {query}")
            return self.rag_storage.search_judgements(query, n_results=max_judgements)
        
        

        # Configure Vision API
        vision_api_key = os.getenv("GOOGLE_CLOUD_VISION_API_KEY")
        if not vision_api_key:
            raise Exception("Google Cloud Vision API key not found. Please set GOOGLE_CLOUD_VISION_API_KEY in your .env file")
        
        self.vision_client = ImageAnnotatorClient(client_options={"api_key": vision_api_key})
        self.image_context = {"language_hints": ["he"]} 

    def process_document(self, files: Union[UploadFile, List[UploadFile]], doc_types: Union[str, List[str]], compress: bool = False) -> Dict[str, str]:
        """Process uploaded documents and extract text"""
        if not files:
            raise HTTPException(
                status_code=400,
                detail="At least one document must be provided"
            )
          # Handle single file case
        if isinstance(files, UploadFile):
            files = [files]
            doc_types = [doc_types]
        elif not isinstance(doc_types, list):
            doc_types = [doc_types] * len(files)
        
        # Initialize text storage
        payslip_text = None
        contract_text = None
        attendance_text = None
        
        # Initialize counters
        payslip_counter = 0
        contract_counter = 0
        attendance_counter = 0
        # Process each file based on its type
        for file, doc_type in zip(files, doc_types):
            print(f"Processing file: {file.filename} as type: {doc_type}")
            extracted_text = self._extract_text2(file.file.read(), file.filename, compress=compress)
            if doc_type.lower() == "payslip":
                payslip_counter += 1
                payslip_text = f"Payslip {payslip_counter}:\n{extracted_text}" if payslip_text is None else f"{payslip_text}\n\nPayslip {payslip_counter}:\n{extracted_text}"
            elif doc_type.lower() == "contract":
                contract_counter += 1
                contract_text = f"Contract {contract_counter}:\n{extracted_text}" if contract_text is None else f"{contract_text}\n\nContract {contract_counter}:\n{extracted_text}"
            elif doc_type.lower() == "attendance":
                attendance_counter += 1
                attendance_text = f"Attendance {attendance_counter}:\n{extracted_text}" if attendance_text is None else f"{attendance_text}\n\nAttendance {attendance_counter}:\n{extracted_text}"
        
        return {
            "payslip_text": payslip_text,
            "contract_text": contract_text,
            "attendance_text": attendance_text
        }

    async def create_report(self, payslip_text: str = None, contract_text: str = None, 
                          attendance_text: str = None, analysis_type: str = "report", 
                          context: str = None) -> DocumentAnalysisResponse:
        """Create legal analysis report using RAG and PydanticAI"""
        
        # Prepare documents for analysis
        documents = {}
        if payslip_text:
            documents['payslip'] = payslip_text
        if contract_text:
            documents['contract'] = contract_text
        if attendance_text:
            documents['attendance report'] = attendance_text        # Pass the string to the context agent instead of the dictionary
        docs= "\n\n".join([f"{doc_type.upper()} CONTENT:\n{content}" for doc_type, content in documents.items()])
        context_result = await self.context_agent.run(docs)

        # Extract the string data from the result object
        ai_context = str(context_result.data) if hasattr(context_result, 'data') else str(context_result)

        print(f"Retrieving laws for context: {ai_context}")

        # Retrieve relevant laws and judgements using RAG
        # relevant_laws, relevant_judgements = self.rag_storage.get_relevant_context(
        #     query, max_laws=5, max_judgements=3
        # )
        
        # # Format retrieved content for prompt
        # formatted_laws = self.rag_storage.format_laws_for_prompt(relevant_laws)
        # formatted_judgements = self.rag_storage.format_judgements_for_prompt(relevant_judgements)
        
        # Build the analysis prompt based on type
        prompt = await self._build_analysis_prompt(
            analysis_type, documents, ai_context, context
        )
        
        try:
            # Generate analysis using PydanticAI
            try:
                result = await self.agent.run(prompt)
                analysis = result.data
            except Exception as pydantic_error:
                # If PydanticAI fails, check if it's an event loop issue
                if "Event loop is closed" in str(pydantic_error) or "event loop" in str(pydantic_error).lower():
                    # Try to recreate the agent with a fresh context
                    print(pydantic_error)
                    print("Attempting to recreate PydanticAI agent due to event loop issue...")
                      # Create a new agent instance
                    temp_agent = Agent(
                        model=self.model,
                        result_type=str,
                        system_prompt="""You are an expert legal document analyzer specializing in Israeli labor law compliance.

You will be provided with:
1. Relevant labor laws retrieved from a legal database
2. Relevant legal judgements and precedents retrieved from a legal database  
3. Document content to analyze (payslips, contracts, attendance records)
4. Additional context if provided

Your analysis must be based STRICTLY on the provided laws and judgements. Do not use external legal knowledge.

Always respond in Hebrew and follow the specific formatting requirements for each analysis type."""
                    )
                      # Try the request again with the fresh agent
                    result = await temp_agent.run(prompt)
                    analysis = result.data
                else:
                    # Re-raise the original error if it's not event loop related
                    raise pydantic_error
            
            return DocumentAnalysisResponse(
                legal_analysis=analysis,
                # relevant_laws=relevant_laws,
                # relevant_judgements=relevant_judgements,
                status="success",
                analysis_type=analysis_type
            )
            
        except Exception as e:
            raise HTTPException(
                status_code=500,
                detail=f"Error generating legal analysis: {str(e)}"
            )

    async def _build_analysis_prompt(self, analysis_type: str, documents: Dict, 
                                   ai_context: str, 
                                   context: str = None) -> str:
        """Build analysis prompt based on type"""
        
        base_prompt = f"""
RELEVANT LABOR LAWS and JUDGEMENTS (Retrieved from legal database):
{ai_context}


DOCUMENTS PROVIDED FOR ANALYSIS:
{', '.join(documents.keys())}

ADDITIONAL CONTEXT:
{context if context else 'No additional context provided.'}
"""
        # Add document contents to prompt
        for doc_type, content in documents.items():
            base_prompt += f"\n{doc_type.upper()} CONTENT:\n{content}\n"
        
        # Add specific instructions based on analysis type
        if analysis_type == 'report':
            base_prompt += self._get_report_instructions()
        elif analysis_type == 'profitability':
            base_prompt += self._get_profitability_instructions()
        elif analysis_type == 'professional':
            base_prompt += self._get_professional_instructions()
        elif analysis_type == 'warning_letter':
            base_prompt += await self._get_warning_letter_instructions()
        elif analysis_type == 'easy':
            base_prompt += self._get_easy_instructions()
        elif analysis_type == 'table':
            base_prompt += self._get_table_instructions()
        elif analysis_type == 'claim':
            base_prompt += self._get_claim_instructions()
        
        return base_prompt

    def _get_report_instructions(self) -> str:
        return """
INSTRUCTIONS:
1. If no labor laws are provided, respond with: "××™×Ÿ ×—×•×§×™× ×œ×¢×‘×•×“×” ×–×ž×™× ×™× ×œ× ×™×ª×•×— ×”×ª××ž×”." in Hebrew.
2. If labor laws exist, analyze the documents ONLY against the provided laws.
3. ONLY refer to the judgements and their results provided above for legal analysis - do not use external cases or knowledge.
4. If no judgements are provided, respond with: "×œ× ×§×™×™×ž×•×ª ×”×—×œ×˜×•×ª ×ž×©×¤×˜×™×•×ª ×–×ž×™× ×•×ª ×œ× ×™×ª×•×—." in Hebrew.

For each payslip provided, analyze and identify violations. For each violation found in each payslip, format the response EXACTLY as shown below, with each section on a new line and proper spacing:

Violation Format Template:

[VIOLATION TITLE]

[SPECIFIC VIOLATION DETAILS]

[LAW REFERENCE AND YEAR FROM PROVIDED LAWS]

[SIMILAR CASES OR PRECEDENTS FROM PROVIDED JUDGEMENTS](Refer *only* to the retrieved judgements. If a relevant judgement is found, describe the case and its result. If no relevant judgement is found, state "×œ× × ×ž×¦××• ×ª×§×“×™×ž×™× ×¨×œ×•×•× ×˜×™×™× ×‘×¤×¡×§×™ ×”×“×™×Ÿ ×©×¡×•×¤×§×•.")

[LEGAL IMPLICATIONS BASED ON PROVIDED INFORMATION]

[RECOMMENDED ACTIONS]

---

IMPORTANT:
- Always Respond in Hebrew
- Format each violation with proper spacing and line breaks as shown above
- Analyze each payslip separately and clearly indicate which payslip the violations belong to
- Separate multiple violations with '---'
- If no violations are found against the provided laws in a payslip, respond with: "×œ× × ×ž×¦××• ×”×¤×¨×•×ª ×‘×ª×œ×•×© ×ž×¡×¤×¨ [X]" in hebrew
- If no violations are found in any payslip, respond with: "×œ× × ×ž×¦××• ×”×¤×¨×•×ª × ×’×“ ×—×•×§×™ ×”×¢×‘×•×“×” ×©×¡×•×¤×§×•." in hebrew
- Do not include any additional commentary or explanations outside of the violation format
"""

    def _get_profitability_instructions(self) -> str:
        return """
INSTRUCTIONS:
1. Analyze the provided documents and identify potential labor law violations, based *exclusively on the retrieved LABOR LAWS and JUDGEMENTS*.
2. For each violation, refer *only* to the retrieved judgements to identify similar legal cases and their outcomes (both successful and unsuccessful).
3. If similar cases (from the retrieved judgements) were unsuccessful:
   - Explain why the cases were unsuccessful based on the retrieved judgement information.
   - Provide a clear recommendation against pursuing legal action based on this.
   - List potential risks and costs.

4. If similar cases (from the retrieved judgements) were successful, calculate using information from those judgements if available:
   - Average compensation amount from successful retrieved cases.
   - Estimated legal fees (30% of potential compensation).
   - Tax implications (25% of net compensation).
   - Time and effort cost estimation.

Provide the analysis in the following format:

× ×™×ª×•×— ×›×“××™×•×ª ×›×œ×›×œ×™×ª:

×”×¤×¨×•×ª ×©×–×•×”×• (×¢×œ ×‘×¡×™×¡ ×”×—×•×§×™× ×©×¡×•×¤×§×•):
[List identified violations]

×ª×§×“×™×ž×™× ×ž×©×¤×˜×™×™× (×ž×ª×•×š ×¤×¡×§×™ ×”×“×™×Ÿ ×©×¡×•×¤×§×•):
[Similar cases from retrieved judgements with outcomes - both successful and unsuccessful]

×‘×ž×§×¨×” ×©×œ ×ª×§×“×™×ž×™× ×©×œ×™×œ×™×™× (×ž×ª×•×š ×¤×¡×§×™ ×”×“×™×Ÿ ×©×¡×•×¤×§×•):
- ×¡×™×‘×•×ª ×œ×“×—×™×™×ª ×”×ª×‘×™×¢×•×ª: [REASONS BASED ON RETRIEVED JUDGEMENTS]
- ×¡×™×›×•× ×™× ××¤×©×¨×™×™×: [RISKS]
- ×”×ž×œ×¦×”: ×œ× ×ž×•×ž×œ×¥ ×œ×”×’×™×© ×ª×‘×™×¢×” ×‘×©×œ [EXPLANATION BASED ON RETRIEVED JUDGEMENTS]

×‘×ž×§×¨×” ×©×œ ×ª×§×“×™×ž×™× ×—×™×•×‘×™×™× (×ž×ª×•×š ×¤×¡×§×™ ×”×“×™×Ÿ ×©×¡×•×¤×§×•):
× ×™×ª×•×— ×›×¡×¤×™:
- ×¡×›×•× ×¤×™×¦×•×™ ×ž×ž×•×¦×¢ (×ž×¤×¡×™×§×•×ª ×“×™×Ÿ ×©×¡×•×¤×§×•): [AMOUNT] â‚ª
- ×¢×œ×•×ª ×ž×©×•×¢×¨×ª ×©×œ ×¢×•×¨×š ×“×™×Ÿ (30%): [AMOUNT] â‚ª
- ×”×©×œ×›×•×ª ×ž×¡ (25% ×ž×”×¡×›×•× × ×˜×•): [AMOUNT] â‚ª
- ×¡×›×•× × ×˜×• ×ž×©×•×¢×¨: [AMOUNT] â‚ª

×”×ž×œ×¦×” ×¡×•×¤×™×ª:
[Based on analysis of both successful and unsuccessful cases from the retrieved judgements, provide clear recommendation]
"""

    def _get_professional_instructions(self) -> str:
        return """
Analyze the provided documents for labor law violations based strictly on the retrieved Israeli labor laws and the content of the documents. For each violation, calculate the monetary differences using only those laws.
Provide your analysis in the following format, entirely in Hebrew:

× ×™×ª×•×— ×ž×§×¦×•×¢×™ ×©×œ ×”×¤×¨×•×ª ×©×›×¨:

×”×¤×¨×”: [×›×•×ª×¨×ª ×”×”×¤×¨×”]
[×ª×™××•×¨ ×ž×¤×•×¨×˜ ×©×œ ×”×”×¤×¨×”, ×›×•×œ×œ ×ª××¨×™×›×™× ×¨×œ×•×•× ×˜×™×™×, ×©×¢×•×ª ×¢×‘×•×“×”, ×©×›×¨ ×©×¢×ª×™ ×•×—×™×©×•×‘×™×, ×‘×”×ª×‘×¡×¡ ××š ×•×¨×§ ×¢×œ ×”×—×•×§×™× ×”×™×©×¨××œ×™×™× ×©× ×ž×¦××• ×•×”×ž×¡×ž×›×™× ×©×¡×•×¤×§×•.
×“×•×’×ž×”: ×”×¢×•×‘×“ ×¢×‘×“ X ×©×¢×•×ª × ×•×¡×¤×•×ª ×‘×™×Ÿ [×—×•×“×© ×©× ×”] ×œ-[×—×•×“×© ×©× ×”]. ×œ×¤×™ ×©×›×¨ ×©×¢×ª×™ ×‘×¡×™×¡×™ ×©×œ [×©×›×¨] â‚ª ×•×©×™×¢×•×¨×™ ×ª×©×œ×•× ×©×¢×•×ª × ×•×¡×¤×•×ª ([×©×™×¢×•×¨1]% ×¢×‘×•×¨ X ×”×©×¢×•×ª ×”×¨××©×•× ×•×ª, [×©×™×¢×•×¨2]% ×œ××—×¨ ×ž×›×Ÿ) ×›×¤×™ ×©×ž×•×¤×™×¢ ×‘×—×•×§×™ ×”×¢×‘×•×“×” ×©× ×ž×¦××•, ×”×¢×•×‘×“ ×”×™×” ×–×›××™ ×œ-[×¡×›×•×] â‚ª ×œ×—×•×“×©. ×‘×¤×•×¢×œ ×§×™×‘×œ ×¨×§ [×¡×›×•× ×©×§×™×‘×œ] â‚ª ×œ×ž×©×š X ×—×•×“×©×™× ×•-[×¡×›×•×] â‚ª ×‘×—×•×“×© [×—×•×“×©].]
×¡×”"×› ×—×•×‘: [×¡×›×•× ×”×”×¤×¨×© ×¢×‘×•×¨ ×”×¤×¨×” ×–×•] â‚ª

×”×¤×¨×”: [×›×•×ª×¨×ª ×”×”×¤×¨×”]
[×ª×™××•×¨ ×ž×¤×•×¨×˜ ×©×œ ×”×”×¤×¨×”, ×›×•×œ×œ ×ª××¨×™×›×™× ×•×—×™×©×•×‘×™×, ×‘×”×ª×‘×¡×¡ ××š ×•×¨×§ ×¢×œ ×”×—×•×§×™× ×©× ×ž×¦××• ×•×”×ž×¡×ž×›×™×. 
×“×•×’×ž×”: ×‘×—×•×“×© [×—×•×“×© ×©× ×”] ×œ× ×‘×•×¦×¢×” ×”×¤×§×“×” ×œ×¤× ×¡×™×”. ×”×ž×¢×¡×™×§ ×ž×—×•×™×‘ ×œ×”×¤×§×™×“ [××—×•×–]% ×ž×”×©×›×¨ ×‘×’×•×‘×” [×©×›×¨] â‚ª = [×¡×›×•×] â‚ª ×‘×”×ª×× ×œ×—×•×§/×¦×• ×”×¨×—×‘×” ×©× ×ž×¦×.]
×¡×”"×› ×—×•×‘ ×¤× ×¡×™×”: [×¡×›×•× ×—×•×‘ ×”×¤× ×¡×™×” ×œ×”×¤×¨×” ×–×•] â‚ª

---

×¡×”"×› ×ª×‘×™×¢×” ×ž×©×¤×˜×™×ª (×œ× ×›×•×œ×œ ×¨×™×‘×™×ª): [×”×¡×›×•× ×”×›×•×œ×œ ×œ×ª×‘×™×¢×” ×ž×›×œ×œ ×”×”×¤×¨×•×ª] â‚ª  
××¡×ž×›×ª××•×ª ×ž×©×¤×˜×™×•×ª: [×¨×©×™×ž×ª ×©×ž×•×ª ×”×—×•×§ ×”×¨×œ×•×•× ×˜×™×™× ×ž×ª×•×š ×”×—×•×§×™× ×”×™×©×¨××œ×™×™× ×©× ×ž×¦××•. ×œ×“×•×’×ž×”: ×—×•×§ ×©×¢×•×ª ×¢×‘×•×“×” ×•×ž× ×•×—×”, ×¦×• ×”×¨×—×‘×” ×œ×¤× ×¡×™×” ×—×•×‘×”]
"""

    async def _get_warning_letter_instructions(self) -> str:
        # Get letter format from storage (we'll need to adapt this)
        # For now, using a default template
        format_content = """
[×ª××¨×™×š]

×œ×›×‘×•×“
[×©× ×”×ž×¢×¡×™×§]
[×›×ª×•×‘×ª ×”×ž×¢×¡×™×§]

×”× ×“×•×Ÿ: ×”×ª×¨××” ×‘×’×™×Ÿ ×”×¤×¨×•×ª ×—×•×§×™ ×¢×‘×•×“×”

×‘×”×ª×‘×¡×¡ ×¢×œ ×‘×“×™×§×ª ×”×ž×¡×ž×›×™× ×©×‘×™×“×™× ×•, × ×ž×¦××• ×”×¤×¨×•×ª ×©×œ ×—×•×§×™ ×¢×‘×•×“×” ×›×ž×¤×•×¨×˜ ×œ×”×œ×Ÿ:

[×¤×¨×˜×™ ×”×”×¤×¨×•×ª]

×”×¤×¨×•×ª ××œ×• ×ž×”×•×•×ª ×”×¤×¨×” ×©×œ:
[×”×¤× ×™×•×ª ×œ×—×•×§×™×]

×‘×”×ª×× ×œ×›×š, ×× ×• ×“×•×¨×©×™× ×›×™ ×ª×ª×§× ×• ××ª ×”×”×¤×¨×•×ª ×”× "×œ ×ª×•×š [×ž×•×¢×“] ×™×ž×™× ×ž×§×‘×œ×ª ×ž×›×ª×‘ ×–×”.

××™ ×ª×™×§×•×Ÿ ×”×”×¤×¨×•×ª ×¢×œ×•×œ ×œ×”×•×‘×™×œ ×œ× ×§×™×˜×ª ×”×œ×™×›×™× ×ž×©×¤×˜×™×™×.

×‘×›×‘×•×“,
[×—×ª×™×ž×”]
"""
        
        return f"""
INSTRUCTIONS:
1. Analyze the provided documents for labor law violations *based exclusively on the retrieved LABOR LAWS and JUDGEMENTS*.
2. If violations are found, generate a formal warning letter using the provided template.
3. If no violations are found, respond with: "×œ× × ×ž×¦××• ×”×¤×¨×•×ª ×”×ž×¦×“×™×§×•×ª ×ž×›×ª×‘ ×”×ª×¨××”." in Hebrew.

Warning Letter Template:
{format_content}

Please generate the warning letter in Hebrew with the following guidelines:
- Replace [×©× ×”×ž×¢×¡×™×§] with the employer's name from the documents
- Replace [×¤×¨×˜×™ ×”×”×¤×¨×•×ª] with specific details of each violation found (based on retrieved laws)
- Replace [×”×¤× ×™×•×ª ×œ×—×•×§×™×] with relevant labor law citations *from the retrieved LABOR LAWS*.
- Replace [×ž×•×¢×“] with a reasonable timeframe for corrections (typically 14 days)
- Maintain a professional and formal tone throughout
- Include all violations found in the analysis (based on retrieved laws)
- Format the letter according to the provided template structure
"""

    def _get_easy_instructions(self) -> str:
        return """
ðŸ”’ ×ž×˜×¨×”: ×¦×•×¨ ×¡×™×›×•× ×§×¦×¨ ×•×‘×¨×•×¨ ×©×œ ×”×”×¤×¨×•×ª ×‘×ª×œ×•×©×™ ×”×©×›×¨ ×©×œ ×”×¢×•×‘×“.
ðŸ“Œ ×›×œ×œ×™× ×ž×—×™×™×‘×™×:
	1. ×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×‘×œ×‘×“ â€“ ××œ ×ª×©×ª×ž×© ×‘×× ×’×œ×™×ª ×‘×›×œ×œ.
	2. ×¢×‘×•×¨ ×›×œ ×—×•×“×© ×”×¦×’ ××ª ×”×”×¤×¨×•×ª ×‘×©×•×¨×•×ª × ×¤×¨×“×•×ª, ×›×œ ×©×•×¨×” ×‘×¤×•×¨×ž×˜ ×”×‘×:
âŒ [×¡×•×’ ×”×”×¤×¨×” ×‘×§×¦×¨×”] â€“ [×¡×›×•× ×‘×©"×— ×¢× â‚ª, ×›×•×œ×œ ×¤×¡×™×§ ×œ××œ×¤×™×]
×œ×“×•×’×ž×”: âŒ ×œ× ×©×•×œ× ×”×—×–×¨ × ×¡×™×¢×•×ª ×‘×¤×‘×¨×•××¨ 2025 â€“ 250 â‚ª
	3. ×× ×™×© ×ž×¡×¤×¨ ×¨×›×™×‘×™ ×¤× ×¡×™×” (×¢×•×‘×“/×ž×¢×¡×™×§/×‘×¨×™××•×ª) ×‘×—×•×“×© ×ž×¡×•×™× â€“ ×—×‘×¨ ××•×ª× ×œ×¡×›×•× ××—×“ ×©×œ ×¤× ×¡×™×” ×‘××•×ª×• ×”×—×•×“×©.
	4. ×›×œ ×”×¡×›×•×ž×™× ×™×•×¦×’×• ×¢× ×¤×¡×™×§×™× ×œ××œ×¤×™× ×•×¢× â‚ª ×‘×¡×•×£.
	5. ×—×™×©×•×‘ ×”×¡×›×•× ×”×›×•×œ×œ ×™×•×¤×™×¢ ×‘×©×•×¨×” × ×¤×¨×“×ª:
ðŸ’° ×¡×”"×›: [×¡×›×•× ×›×•×œ×œ] â‚ª
	6. ×”×•×¡×£ ×”×ž×œ×¦×” ×‘×¡×•×£:
ðŸ“ ×ž×” ×œ×¢×©×•×ª ×¢×›×©×™×•:
×¤× ×”/×™ ×œ×ž×¢×¡×™×§ ×¢× ×“×¨×™×©×” ×œ×ª×©×œ×•× ×”×¡×›×•×ž×™×.
×× ××™×Ÿ ×ž×¢× ×” â€“ ×ž×•×ž×œ×¥ ×œ×¤× ×•×ª ×œ×™×™×¢×•×¥ ×ž×©×¤×˜×™.
ðŸ“ ×”× ×—×™×•×ª × ×•×¡×¤×•×ª:
	â€¢ ××™×Ÿ ×œ×›×ª×•×‘ ×ž×¡×¤×¨×™× ×‘×œ×™ ×”×§×©×¨, ×›×œ ×©×•×¨×” ×—×™×™×‘×ª ×œ×”×™×•×ª ×ž×œ×•×•×” ×‘×—×•×“×©.
	â€¢ ×ž×™×–×•×’ ×©×•×¨×•×ª: ×× ×‘××•×ª×• ×—×•×“×© ×™×© ×›×ž×” ×¨×›×™×‘×™× ×©×œ ×¤× ×¡×™×” â€“ ×ž×™×–×’ ××•×ª× ×œ×©×•×¨×” ××—×ª.
	â€¢ ×”×¡×¨ ×©×•×¨×•×ª ×œ×œ× ×¡×›×•× ×‘×¨×•×¨.
	â€¢ × ×™×¡×•×— ×¤×©×•×˜, ×œ×œ× ×ž×™× ×•×—×™× ×ž×©×¤×˜×™×™×, ×”×‘×”×¨×•×ª ××• ×”×¡×‘×¨×™× ×˜×›× ×™×™×.
	â€¢ ××™×Ÿ ×œ×¦×™×™×Ÿ "×¨×›×™×‘ ×¢×•×‘×“", "×¨×›×™×‘ ×ž×¢×¡×™×§", "×œ× ×”×•×¤×§×“" â€“ ×‘×ž×§×•× ×–××ª ×›×ª×•×‘: "×œ× ×©×•×œ×ž×” ×¤× ×¡×™×”".
ðŸŽ¯ ×¤×œ×˜ ×¨×¦×•×™:
	â€¢ ×©×•×¨×•×ª ×ž×¡×•×“×¨×•×ª ×œ×¤×™ ×—×•×“×©×™×
	â€¢ ××™×Ÿ ×›×¤×™×œ×•×™×•×ª
	â€¢ ×¡×›×•×ž×™× ×ž×“×•×™×§×™× ×‘×œ×‘×“
	â€¢ × ×™×¡×•×— ×‘×¨×•×¨ ×•×ž×•×‘×Ÿ
	â€¢ ×¢×‘×¨×™×ª ×‘×œ×‘×“

ðŸ§ª Example of desired output:
ðŸ“¢ ×¡×™×›×•× ×”×”×¤×¨×•×ª:
âŒ ×œ× ×©×•×œ× ×¢×‘×•×¨ ×©×¢×•×ª × ×•×¡×¤×•×ª ×‘× ×•×‘×ž×‘×¨ 2024 â€“ 495 â‚ª
âŒ ×œ× ×©×•×œ×ž×” ×¤× ×¡×™×” ×‘× ×•×‘×ž×‘×¨ 2024 â€“ 750 â‚ª
âŒ ×œ× ×©×•×œ×ž×” ×¤× ×¡×™×” ×‘×“×¦×ž×‘×¨ 2024 â€“ 1,221 â‚ª
âŒ ×œ× ×©×•×œ×ž×” ×¤× ×¡×™×” ×‘×™× ×•××¨ 2025 â€“ 831 â‚ª
âŒ ×œ× ×©×•×œ× ×”×—×–×¨ × ×¡×™×¢×•×ª ×‘×¤×‘×¨×•××¨ 2025 â€“ 250 â‚ª
âŒ ×œ× ×©×•×œ×ž×” ×¤× ×¡×™×” ×‘×¤×‘×¨×•××¨ 2025 â€“ 858 â‚ª
âŒ ×œ× ×©×•×œ×ž×” ×¤× ×¡×™×” ×‘×ž×¨×¥ 2025 â€“ 866 â‚ª
ðŸ’° ×¡×”"×›: 5,271 â‚ª
ðŸ“ ×ž×” ×œ×¢×©×•×ª ×¢×›×©×™×•:
×¤× ×”/×™ ×œ×ž×¢×¡×™×§ ×¢× ×“×¨×™×©×” ×œ×ª×©×œ×•× ×”×¡×›×•×ž×™×.
×× ××™×Ÿ ×ž×¢× ×” â€“ ×ž×•×ž×œ×¥ ×œ×¤× ×•×ª ×œ×™×™×¢×•×¥ ×ž×©×¤×˜×™.
"""

    def _get_table_instructions(self) -> str:
        return """
××ª×” ×¢×•×–×¨ ×ž×©×¤×˜×™ ×ž×™×•×ž×Ÿ. ×¢×œ×™×š ×œ× ×ª×— ××ª ×¨×©×™×ž×ª ×”×”×¤×¨×•×ª ×•×œ×”×¤×™×§ ×¨×©×™×ž×ª ×ª×‘×™×¢×•×ª ×ž×¡×•×“×¨×ª ×œ×¤×™ ×ž×¡×ž×š (×œ×“×•×’×ž×”: ×ª×œ×•×© ×©×›×¨ ×ž×¡' 1, ×ž×¡×ž×š ×©×™×ž×•×¢, ×ž×›×ª×‘ ×¤×™×˜×•×¨×™×Ÿ ×•×›×•').

×”× ×—×™×•×ª:

1. ×¡×“×¨ ××ª ×”×ª×‘×™×¢×•×ª ×œ×¤×™ ×ž×¡×ž×š: ×›×œ ×§×‘×•×¦×” ×ž×ª×—×™×œ×” ×‘×›×•×ª×¨×ª ×›×ž×• "×ª×œ×•×© ×©×›×¨ ×ž×¡' 4 â€“ 05/2024:".

2. ×ª×—×ª ×›×œ ×›×•×ª×¨×ª, ×¦×•×¨ ×¨×©×™×ž×” ×ž×ž×•×¡×¤×¨×ª ×‘××•×ª×™×•×ª ×¢×‘×¨×™×•×ª (×., ×‘., ×’. ×•×›×•').

3. ×”×©×ª×ž×© ×‘×ž×‘× ×” ×”×§×‘×•×¢ ×”×‘×:
   ×. ×¡×›×•× ×©×œ [amount] ×©"×— ×¢×‘×•×¨ [×ª×™××•×¨ ×§×¦×¨ ×©×œ ×”×”×¤×¨×”].

4. ×”×©×ª×ž×© ×‘×¤×•×¨×ž×˜ ×ž×¡×¤×¨×™× ×¢× ×¤×¡×™×§×™× ×œ××œ×¤×™× ×•×©×ª×™ ×¡×¤×¨×•×ª ××—×¨×™ ×”× ×§×•×“×” (×œ×ž×©×œ: 1,618.75 ×©"×—).

5. ×›×ª×•×‘ "×©"×—" ××—×¨×™ ×”×¡×›×•× â€” ×œ× â‚ª.

6. ××œ ×ª×¡×›× ××ª ×›×œ×œ ×”×”×¤×¨×•×ª â€“ ×”×¦×’ ×¨×§ ××ª ×”×¤×™×¨×•×˜ ×œ×¤×™ ×ž×¡×ž×š.

7. ××œ ×ª×•×¡×™×£ ×‘×•×œ×˜×™×, ×˜×‘×œ××•×ª ××• ×”×¢×¨×•×ª.

× ×ª×•× ×™ ×”×§×œ×˜ ×œ×“×•×’×ž×”:
âŒ ××™ ×ª×©×œ×•× ×©×¢×•×ª × ×•×¡×¤×•×ª (×ª×œ×•×© 6, 11/2024) â€“ 495 ×©"×—
âŒ ×”×¢×“×¨ ×¨×›×™×‘ ×ž×¢×‘×™×“ ×œ×¤× ×¡×™×” (×ª×œ×•×© 6, 11/2024) â€“ 750 ×©"×—
âŒ ×”×¢×“×¨ ×¨×›×™×‘ ×¢×•×‘×“ ×œ×¤× ×¡×™×” (×ª×œ×•×© 7, 12/2024) â€“ 396 ×©"×—
âŒ ×”×¢×“×¨ × ×¡×™×¢×•×ª (×ª×œ×•×© 9, 02/2025) â€“ 250 ×©"×—

×¤×œ×˜ × ×“×¨×© ×œ×“×•×’×ž×”:

×ª×œ×•×© ×©×›×¨ ×ž×¡' 6 â€“ 11/2024:
×. ×¡×›×•× ×©×œ 495.00 ×©"×— ×¢×‘×•×¨ ××™ ×ª×©×œ×•× ×©×¢×•×ª × ×•×¡×¤×•×ª.
×‘. ×¡×›×•× ×©×œ 750.00 ×©"×— ×¢×‘×•×¨ ×”×¢×“×¨ ×¨×›×™×‘ ×ž×¢×‘×™×“ ×œ×¤× ×¡×™×”.

×ª×œ×•×© ×©×›×¨ ×ž×¡' 7 â€“ 12/2024:
×. ×¡×›×•× ×©×œ 396.00 ×©"×— ×¢×‘×•×¨ ×”×¢×“×¨ ×¨×›×™×‘ ×¢×•×‘×“ ×œ×¤× ×¡×™×”.

×ª×œ×•×© ×©×›×¨ ×ž×¡' 9 â€“ 02/2025:
×. ×¡×›×•× ×©×œ 250.00 ×©"×— ×¢×‘×•×¨ ×”×¢×“×¨ ×ª×©×œ×•× ×¢×‘×•×¨ × ×¡×™×¢×•×ª.

×”×—×–×¨ ××ª ×”×¤×œ×˜ ×‘×¤×•×¨×ž×˜ ×–×” ×‘×œ×‘×“, ×ž×•×¤×¨×“ ×œ×¤×™ ×›×œ ×ž×¡×ž×š.
"""

    def _get_claim_instructions(self) -> str:
        return """
×ž×©×™×ž×”:
×›×ª×•×‘ ×˜×™×•×˜×ª ×›×ª×‘ ×ª×‘×™×¢×” ×œ×‘×™×ª ×”×“×™×Ÿ ×”××–×•×¨×™ ×œ×¢×‘×•×“×”, ×‘×”×ª×× ×œ×ž×‘× ×” ×”×ž×©×¤×˜×™ ×”× ×”×•×’ ×‘×™×©×¨××œ.

× ×ª×•× ×™×:
×”×©×ª×ž×© ×‘×ž×™×“×¢ ×ž×ª×•×š ×”×ž×¡×ž×›×™× ×©×¦×•×¨×¤×• (×›×’×•×Ÿ ×ª×œ×•×©×™ ×©×›×¨, ×”×¡×›×ž×™ ×¢×‘×•×“×”, ×”×•×“×¢×•×ª ×¤×™×˜×•×¨×™×Ÿ, ×©×™×—×•×ª ×¢× ×”×ž×¢×¡×™×§) ×•×‘×ž×ž×¦××™× ×©× ×ž×¦××• ×‘× ×™×ª×•×— ×§×•×“× ×©×œ ×”×”×¤×¨×•×ª.

×¤×•×¨×ž×˜ ×œ×›×ª×™×‘×”:
1. ×›×•×ª×¨×ª: "×‘×™×ª ×”×“×™×Ÿ ×”××–×•×¨×™ ×œ×¢×‘×•×“×” ×‘[×©× ×¢×™×¨]"
2. ×¤×¨×˜×™ ×”×ª×•×‘×¢/×ª:
   - ×©× ×ž×œ×, ×ª"×–, ×›×ª×•×‘×ª, ×˜×œ×¤×•×Ÿ, ×ž×™×™×œ
3. ×¤×¨×˜×™ ×”× ×ª×‘×¢/×ª (×ž×¢×¡×™×§):
   - ×©× ×”×—×‘×¨×”/×ž×¢×¡×™×§, ×—.×¤./×ª"×–, ×›×ª×•×‘×ª, ×˜×œ×¤×•×Ÿ, ×ž×™×™×œ (×× ×§×™×™×)
4. ×›×•×ª×¨×ª: "×›×ª×‘ ×ª×‘×™×¢×”"
5. ×¤×ª×™×— ×ž×©×¤×˜×™:
   ×‘×™×ª ×”×“×™×Ÿ ×”× ×›×‘×“ ×ž×ª×‘×§×© ×œ×–×ž×Ÿ ××ª ×”× ×ª×‘×¢/×ª ×œ×“×™×Ÿ ×•×œ×—×™×™×‘×•/×” ×œ×©×œ× ×œ×ª×•×‘×¢/×ª ××ª ×”×¡×›×•×ž×™× ×”×ž×¤×•×¨×˜×™×, ×ž×”× ×™×ž×•×§×™× ×”×‘××™×:
6. ×¡×¢×™×£ 1 â€“ ×¨×§×¢ ×¢×•×‘×“×ª×™:
   ×ª×™××•×¨ ×ª×§×•×¤×ª ×”×¢×‘×•×“×”, ×ª×¤×§×™×“×™×, ×ª××¨×™×š ×ª×—×™×œ×” ×•×¡×™×•× (×× ×¨×œ×•×•× ×˜×™), ×ž×”×•×ª ×™×—×¡×™ ×”×¢×‘×•×“×”, ×ž×§×•× ×”×¢×‘×•×“×”.
7. ×¡×¢×™×£ 2 â€“ ×¢×™×œ×•×ª ×”×ª×‘×™×¢×” (×œ×¤×™ ×”×¤×¨×•×ª):
   ×œ×›×œ ×”×¤×¨×”:
     - ××™×–×” ×—×•×§ ×”×•×¤Öµ×¨ (×œ×“×•×’': ×—×•×§ ×©×›×¨ ×ž×™× ×™×ž×•×, ×—×•×§ ×©×¢×•×ª ×¢×‘×•×“×” ×•×ž× ×•×—×” ×•×›×•')
     - ×¤×™×¨×•×˜ ×”×¢×•×‘×“×•×ª ×•×”×ª×§×•×¤×” ×”×¨×œ×•×•× ×˜×™×ª
     - ×¡×›×•× ×”×¤×™×¦×•×™ ××• ×”× ×–×§
     - ××¡×ž×›×ª××•×ª ×ž×©×¤×˜×™×•×ª ×× ×¨×œ×•×•× ×˜×™
8. ×¡×¢×™×£ 3 â€“ × ×–×§×™× ×©× ×’×¨×ž×•:
   ×¡×›×•×ž×™× ×›×¡×¤×™×™× (×‘×¤×™×¨×•×˜), × ×–×§ ×œ× ×ž×ž×•× ×™ ×× ×§×™×™× (×¢×•×’×ž×ª × ×¤×©).
9. ×¡×¢×™×£ 4 â€“ ×¡×¢×“×™× ×ž×‘×•×§×©×™×:
   ×ª×©×œ×•× ×”×¤×¨×©×™×, ×¤×™×¦×•×™×™×, ×¨×™×‘×™×ª ×•×”×¦×ž×“×”, ×”×•×¦××•×ª ×ž×©×¤×˜, ×©×›×¨ ×˜×¨×—×ª ×¢×•"×“, ×•×›×œ ×¡×¢×“ ××—×¨.
10. ×¡×¢×™×£ 5 â€“ ×¡×ž×›×•×ª ×©×™×¤×•×˜:
   ×¦×™×™×Ÿ ×¡×ž×›×•×ª ×‘×™×ª ×”×“×™×Ÿ ×œ×¢×‘×•×“×” ×œ×¤×™ ×—×•×§ ×‘×™×ª ×”×“×™×Ÿ ×œ×¢×‘×•×“×” ×ª×©×›"×˜â€“1969.
11. ×¡×¢×™×£ 6 â€“ ×“×™×•×Ÿ ×ž×§×“×™×/×”×œ×™×š ×ž×”×™×¨ (×× ×¨×œ×•×•× ×˜×™).
12. ×¡×¢×™×£ 7 â€“ ×›×ª×•×‘×•×ª ×œ×”×ž×¦××ª ×›×ª×‘×™ ×‘×™-×“×™×Ÿ:
   ×›×ª×•×‘×ª ×”×ª×•×‘×¢ ×•×”× ×ª×‘×¢.
13. ×¡×™×•×:
   ×—×ª×™×ž×”, ×ª××¨×™×š, ×¨×©×™×ž×ª × ×¡×¤×—×™× ×ª×•×ž×›×™× (×ª×œ×•×©×™ ×©×›×¨, ×ž×›×ª×‘×™× ×•×›×•').

×©×¤×”:
- ×›×ª×•×‘ ×‘×¢×‘×¨×™×ª ×ž×©×¤×˜×™×ª, ×¨×©×ž×™×ª ×•×ž×¡×•×“×¨×ª.
- ×¡×“×¨ ××ª ×”×ª×‘×™×¢×” ×¢× ×›×•×ª×¨×•×ª, ×¡×¢×™×¤×™× ×ž×ž×•×¡×¤×¨×™× ×•×¨×•×•×—×™× ×‘×¨×•×¨×™×.
- ××œ ×ª×ž×¦×™× ×¢×•×‘×“×•×ª ××• ×—×•×§×™×. ×× ×—×¡×¨ ×ž×™×“×¢ â€“ ×”×©××¨ ×©×“×” ×¨×™×§ ×œ×¦×•×¨×š ×”×©×œ×ž×” ×¢"×™ ×”×ž×©×ª×ž×©.

××–×”×¨×”:
×‘×¡×™×•×, ×›×ª×•×‘ ×ž×©×¤×˜: "×”×˜×™×•×˜×” × ×›×ª×‘×” ××•×˜×•×ž×˜×™×ª ×œ×¦×•×¨×š ×¢×–×¨×” ×¨××©×•× ×™×ª ×‘×œ×‘×“. ×ž×•×ž×œ×¥ ×œ×¤× ×•×ª ×œ×¢×•×¨×š/×ª ×“×™×Ÿ ×ž×•×¡×ž×š/×ª ×œ×¤× ×™ ×”×’×©×” ×œ×‘×™×ª ×”×“×™×Ÿ."
"""

    def _extract_text2(self, content: bytes, filename: str, compress: bool = False) -> str:
        """Extract text from various document formats using AgenticDoc for PDFs and images"""
        print("Extracting text from file:", filename.lower())
        
        try:
            if filename.lower().endswith(('.pdf', '.png', '.jpg', '.jpeg')):
                # Pass bytes directly to AgenticDoc
                print("Extracting text from image or PDF...")
                
                result = parse(content)
                # Return markdown or structured, as you prefer
                return result[0].markdown
            elif filename.lower().endswith('.docx'):
                doc_file = BytesIO(content)
                doc = Document(doc_file)
                return '\n'.join([p.text for p in doc.paragraphs])
            elif filename.lower().endswith('.xlsx'):
                excel_file = BytesIO(content)
                df = pd.read_excel(excel_file, sheet_name=None)
                text = ""
                for sheet, data in df.items():
                    text += f"Sheet: {sheet}\n"
                    text += data.to_string(index=False) + "\n\n"
                return text
            else:
                # Unknown file type, treat as plain text
                result = parse(content)
                # Return markdown or structured, as you prefer
                return result[0].markdown
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Extraction error: {str(e)}")

    def _extract_text_legacy(self, content: bytes, filename: str, compress: bool = False) -> str:
        """Legacy text extraction method (kept for fallback)"""
        if filename.lower().endswith('.pdf'):
            return self._extract_pdf_text(content)
        elif filename.lower().endswith('.docx'):
            return self._extract_docx_text(content)
        elif filename.lower().endswith('.xlsx'):
            return self._extract_excel_text(content)
        else:
            return self._extract_image_text(content, compress)

    def _extract_pdf_text(self, content: bytes) -> str:
        """Extract text from PDF using pdfplumber and Vision API"""
        try:
            pdf_file = BytesIO(content)
            text = ''
            with pdfplumber.open(pdf_file) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text and page_text.strip():
                        text += page_text + "\n"
                    else:
                        # Convert PDF page to image and use Vision API
                        img = page.to_image(resolution=300).original
                        img_byte_arr = io.BytesIO()
                        img.save(img_byte_arr, format='PNG')
                        img_content = img_byte_arr.getvalue()
                        
                        vision_image = vision.Image(content=img_content)
                        response = self.vision_client.text_detection(image=vision_image, image_context=self.image_context)
                        if response.text_annotations:
                            text_list = [text_annotation.description for text_annotation in response.text_annotations]
                            text += " ".join(text_list) + "\n"
            return text
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Error processing PDF: {str(e)}")

    def _extract_docx_text(self, content: bytes) -> str:
        """Extract text from DOCX files"""
        doc_file = BytesIO(content)
        doc = Document(doc_file)
        return '\n'.join([paragraph.text for paragraph in doc.paragraphs])

    def _extract_excel_text(self, content: bytes) -> str:
        """Extract text from Excel files"""
        try:
            excel_file = BytesIO(content)
            df = pd.read_excel(excel_file, sheet_name=None)  # Load all sheets
            
            text = ""
            for sheet_name, sheet_data in df.items():
                text += f"Sheet: {sheet_name}\n"
                text += sheet_data.to_string(index=False) + "\n\n"
            return text
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Error processing Excel file: {str(e)}")

    def _extract_image_text(self, content: bytes, compress: bool = False) -> str:
        """Extract text from images using Vision API"""
        try:
            if compress:
                content = self._compress_image(content)
            
            vision_image = vision.Image(content=content)
            response = self.vision_client.document_text_detection(image=vision_image, image_context=self.image_context)
            
            if response.error.message:
                raise HTTPException(status_code=500, detail=f"Vision API Error: {response.error.message}")
            
            if response.text_annotations:
                return " ".join([text_annotation.description for text_annotation in response.text_annotations])
            else:
                return ""
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Error processing image: {str(e)}")

    def _compress_image(self, image_bytes: bytes, max_size_mb: int = 4) -> bytes:
        """Compress image to reduce size for API limits"""
        # Convert size to bytes
        max_size_bytes = max_size_mb * 1024 * 1024
        
        # If image is already smaller than max size, return original
        if len(image_bytes) <= max_size_bytes:
            return image_bytes
        
        # Open image using PIL
        img = Image.open(BytesIO(image_bytes))
        
        # Get original dimensions
        width, height = img.size
        
        # Scale down large images while maintaining aspect ratio
        max_dimension = 3000  # Maximum dimension for width or height
        if width > max_dimension or height > max_dimension:
            scale = min(max_dimension / width, max_dimension / height)
            new_width = int(width * scale)
            new_height = int(height * scale)
            img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # Preserve original format if possible
        output_format = img.format or 'JPEG'
        
        # Initial quality and compression settings
        quality = 95
        output = BytesIO()
        
        # Progressive quality reduction with format-specific handling
        while quality > 20:  # Increased minimum quality threshold
            output.seek(0)
            output.truncate(0)
            
            if output_format == 'JPEG':
                img.save(output, format=output_format, quality=quality, optimize=True)
            elif output_format == 'PNG':
                img.save(output, format=output_format, optimize=True)
            else:
                # Default to JPEG for unsupported formats
                img.save(output, format='JPEG', quality=70, optimize=True)
            
            if output.tell() <= max_size_bytes:
                break
            
            # More gradual quality reduction
            quality -= 5
        
        # If still too large, convert to JPEG as last resort
        if output.tell() > max_size_bytes and output_format != 'JPEG':
            output.seek(0)
            output.truncate(0)
            img.save(output, format='JPEG', quality=70, optimize=True)
        
        return output.getvalue()

    async def summarise(self, ai_content_text: str) -> str:
        """
        Summarizes the given text using PydanticAI.
        """
        try:
            prompt = f"Please summarize the following text concisely in Hebrew:\n\n{ai_content_text}"
            
            # Use the same agent for summarization
            try:
                result = await self.agent.run(prompt)
                return result.data if hasattr(result, 'data') else str(result)
            except Exception as pydantic_error:
                # If PydanticAI fails, check if it's an event loop issue
                if "Event loop is closed" in str(pydantic_error) or "event loop" in str(pydantic_error).lower():
                    # Try to recreate the agent with a fresh context
                    print("Attempting to recreate PydanticAI agent for summarization due to event loop issue...")
                    
                    # Create a new agent instance
                    temp_agent = Agent(
                        model=self.model,
                        result_type=str,
                        system_prompt="You are a helpful assistant that summarizes text concisely."
                    )
                    
                    # Try the request again with the fresh agent
                    result = await temp_agent.run(prompt)
                    return result.data if hasattr(result, 'data') else str(result)
                else:
                    # Re-raise the original error if it's not event loop related
                    raise pydantic_error
            
        except Exception as e:
            error_detail = f"Error generating summary with PydanticAI: {str(e)}"
            raise HTTPException(
                status_code=500,
                detail=error_detail
            )
    
    # Sync wrapper methods for backward compatibility
    def create_report_sync(self, payslip_text: str = None, contract_text: str = None, 
                          attendance_text: str = None, type: str = "report", 
                          context: str = None) -> Dict:
        """Synchronous wrapper for create_report method with improved event loop handling"""
        # Handle backward compatibility parameter mapping
        try:
            # Try to get existing event loop
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # If loop is already running, create a new thread
                import concurrent.futures
                import threading
                
                def run_in_thread():
                    # Create new event loop for this thread
                    new_loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(new_loop)
                    try:
                        return new_loop.run_until_complete(self.create_report(
                            payslip_text=payslip_text,
                            contract_text=contract_text, 
                            attendance_text=attendance_text,
                            analysis_type=type,  # Map 'type' to 'analysis_type'
                            context=context
                        ))
                    finally:
                        new_loop.close()
                
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(run_in_thread)
                    result = future.result()
            else:
                # No running loop, use asyncio.run
                result = asyncio.run(self.create_report(
                    payslip_text=payslip_text,
                    contract_text=contract_text, 
                    attendance_text=attendance_text,
                    analysis_type=type,  # Map 'type' to 'analysis_type'
                    context=context
                ))
        except RuntimeError as e:
            if "no current event loop" in str(e).lower() or "event loop is closed" in str(e).lower():
                # Create new event loop
                result = asyncio.run(self.create_report(
                    payslip_text=payslip_text,
                    contract_text=contract_text, 
                    attendance_text=attendance_text,
                    analysis_type=type,  # Map 'type' to 'analysis_type'
                    context=context
                ))
            else:
                raise e
        
        # Convert response to dict for backward compatibility
        return {
            "legal_analysis": result.legal_analysis,
            "status": result.status,
            # "relevant_laws": result.relevant_laws,
            # "relevant_judgements": result.relevant_judgements
        }
    
    def summarise_sync(self, ai_content_text: str) -> str:
        """Synchronous wrapper for summarise method with improved event loop handling"""
        try:
            # Try to get existing event loop
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # If loop is already running, create a new thread
                import concurrent.futures
                
                def run_in_thread():
                    # Create new event loop for this thread
                    new_loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(new_loop)
                    try:
                        return new_loop.run_until_complete(self.summarise(ai_content_text))
                    finally:
                        new_loop.close()
                
                with concurrent.futures.ThreadPoolExecutor() as executor:
                    future = executor.submit(run_in_thread)
                    return future.result()
            else:
                # No running loop, use asyncio.run
                return asyncio.run(self.summarise(ai_content_text))
        except RuntimeError as e:
            if "no current event loop" in str(e).lower() or "event loop is closed" in str(e).lower():
                # Create new event loop
                return asyncio.run(self.summarise(ai_content_text))
            else:
                raise e
